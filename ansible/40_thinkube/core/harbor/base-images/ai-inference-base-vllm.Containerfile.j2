# Copyright 2025 Alejandro Martínez Corriá and the Thinkube contributors
# SPDX-License-Identifier: Apache-2.0

# AI/ML inference base image with vLLM for both AMD64 and ARM64
# Uses NVIDIA NGC vLLM container (multi-arch manifest)
FROM nvcr.io/nvidia/vllm:25.09-py3

# NGC vLLM container already includes:
# - vLLM 0.10.1.1 (pre-compiled for AMD64 and ARM64)
# - PyTorch 2.9.0a0 with CUDA 13.0
# - transformers 4.55.2
# - flash-attention 2.7.4
# - flashinfer 0.4.0
# - xgrammer 0.1.22
# - Python 3.12, Ubuntu 24.04

# Upgrade vLLM to 0.11.0 for latest model support (DeepSeek-V3, Qwen3-VL, OLMo3, etc.)
# This may download a wheel or compile from source depending on compatibility
RUN pip install --no-cache-dir --upgrade vllm==0.11.0

# Install additional ML packages
RUN pip install --no-cache-dir \
    accelerate==0.33.0 \
    gradio==4.42.0 \
    fastapi==0.112.0 \
    uvicorn[standard]==0.30.5

# Install additional utilities
RUN pip install --no-cache-dir \
    numpy==1.26.4 \
    pillow==10.4.0 \
    requests==2.32.3 \
    pyyaml==6.0.2 \
    huggingface-hub==0.24.5 \
    safetensors==0.4.4 \
    sentencepiece==0.2.0 \
    protobuf==5.27.3 \
    psutil==6.0.0

# Set environment variables
ENV PYTHONPATH=/app \
    PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    GRADIO_SERVER_NAME=0.0.0.0 \
    GRADIO_SERVER_PORT=7860 \
    HF_HOME=/app/cache \
    TRANSFORMERS_CACHE=/app/cache

# Create directories
RUN mkdir -p /app/cache /app/models

WORKDIR /app

# Expose default Gradio port
EXPOSE 7860

# Default healthcheck (can be overridden)
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:7860/health || exit 1
