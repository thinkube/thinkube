# Copyright 2025 Alejandro Martínez Corriá and the Thinkube contributors
# SPDX-License-Identifier: Apache-2.0

# AI/ML inference base image for AMD64 with GPU support
# Uses NVIDIA NGC PyTorch container optimized for x86_64 architecture
FROM nvcr.io/nvidia/pytorch:25.09-py3

# NGC container already includes:
# - PyTorch 2.9.0a0 with CUDA 13.0 support for AMD64
# - CUDA toolkit, cuDNN, NCCL, TensorRT
# - Python 3.12, Ubuntu 24.04
# - Optimizations for NVIDIA GPU architectures

# Install core ML packages
RUN pip install --no-cache-dir -q --break-system-packages \
    transformers==4.44.0 \
    accelerate==0.33.0 \
    gradio==4.42.0 \
    fastapi==0.112.0 \
    uvicorn[standard]==0.30.5

# Install vLLM separately as it has complex dependencies
RUN pip install --no-cache-dir -q --break-system-packages vllm==0.5.4

# Install additional utilities
RUN pip install --no-cache-dir -q --break-system-packages \
    numpy==1.26.4 \
    pillow==10.4.0 \
    requests==2.32.3 \
    pyyaml==6.0.2 \
    huggingface-hub==0.24.5 \
    safetensors==0.4.4 \
    sentencepiece==0.2.0 \
    protobuf==5.27.3 \
    psutil==6.0.0

# Set environment variables
ENV PYTHONPATH=/app \
    PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    GRADIO_SERVER_NAME=0.0.0.0 \
    GRADIO_SERVER_PORT=7860 \
    HF_HOME=/app/cache \
    TRANSFORMERS_CACHE=/app/cache

# Create directories
RUN mkdir -p /app/cache /app/models

# Set up healthcheck dependencies (curl already in NGC container)
WORKDIR /app

# Expose default Gradio port
EXPOSE 7860

# Default healthcheck (can be overridden)
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:7860/health || exit 1
