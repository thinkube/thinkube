# Copyright 2025 Alejandro Mart√≠nez Corri√° and the Thinkube contributors
# SPDX-License-Identifier: Apache-2.0

---
# ansible/40_thinkube/core/thinkube-control/11_deploy_webhook_adapter.yaml
# Description:
#   Deploy Harbor webhook adapter for instant image updates via direct Git updates
#   This eliminates the 2-minute polling delay for a true "local development" experience
#   
#   Bootstrap capability: Can deploy before thinkube-control exists. Will initially
#   process webhooks without CI/CD monitoring, then automatically enable full monitoring
#   once thinkube-control creates the required token.
#
# Requirements:
#   - ArgoCD deployed
#   - Harbor registry deployed and accessible
#   - Python base image available in Harbor
#
# Usage:
#   cd ~/thinkube
#   ./scripts/run_ansible.sh ansible/40_thinkube/core/thinkube-control/11_deploy_webhook_adapter.yaml
#
# Variables from inventory:
#   - domain_name: Domain name for all services
#   - harbor_registry: Harbor registry hostname
#   - kubectl_bin: Path to kubectl binary
#   - kubeconfig: Path to Kubernetes configuration file
#
# Dependencies:
#   - CORE-009: ArgoCD deployed
#
# Post-deployment:
#   - When thinkube-control deploys, it creates the CI/CD monitoring token
#   - Webhook adapter automatically detects the token and enables full CI/CD monitoring
#   - Final state: Fully operational CI/CD pipeline with complete monitoring
#
# ü§ñ [AI-assisted]

- name: Deploy Harbor Webhook Adapter
  hosts: microk8s_control_plane
  gather_facts: true
  
  vars:
    adapter_namespace: "{{ argocd_namespace }}"
    adapter_name: "harbor-webhook-adapter"
    
  tasks:
    - name: Get CI/CD monitoring token from thinkube-control namespace
      kubernetes.core.k8s_info:
        kubeconfig: "{{ kubeconfig }}"
        api_version: v1
        kind: Secret
        namespace: "thinkube-control"
        name: "cicd-monitoring-token"
      register: cicd_token_secret
      failed_when: false  # Don't fail if token doesn't exist yet

    - name: Extract CI/CD monitoring token
      ansible.builtin.set_fact:
        cicd_monitoring_token: "{{ cicd_token_secret.resources[0].data.token | b64decode if cicd_token_secret.resources else '' }}"

    - name: Display CI/CD token status
      ansible.builtin.debug:
        msg: "CI/CD monitoring token {{ 'found' if cicd_monitoring_token else 'not found - webhook adapter will work in degraded mode' }}"

    - name: Get sync webhook secret if it exists
      kubernetes.core.k8s_info:
        kubeconfig: "{{ kubeconfig }}"
        api_version: v1
        kind: Secret
        namespace: "{{ adapter_namespace }}"
        name: "sync-webhook-secret"
      register: sync_secret_check

    - name: Set sync webhook secret
      ansible.builtin.set_fact:
        sync_webhook_secret: "{{ sync_secret_check.resources[0].data.webhook_secret | b64decode if sync_secret_check.resources else '' }}"

    - name: Delete existing webhook adapter ConfigMap
      kubernetes.core.k8s:
        kubeconfig: "{{ kubeconfig }}"
        state: absent
        api_version: v1
        kind: ConfigMap
        name: "{{ adapter_name }}-script"
        namespace: "{{ adapter_namespace }}"
      failed_when: false

    - name: Create webhook adapter ConfigMap with Python script
      kubernetes.core.k8s:
        kubeconfig: "{{ kubeconfig }}"
        state: present
        definition:
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: "{{ adapter_name }}-script"
            namespace: "{{ adapter_namespace }}"
            labels:
              version: "0.6.3"  # Support both ci-cd-pipeline and build-and-push templates
          data:
            adapter.py: |
              #!/usr/bin/env python3
              import os
              import sys
              import json
              import logging
              import requests
              import subprocess
              import tempfile
              import base64
              import hmac
              import hashlib
              import time
              import threading
              from http.server import HTTPServer, BaseHTTPRequestHandler
              from urllib.parse import urlparse
              from datetime import datetime
              
              logging.basicConfig(level=logging.INFO)
              logger = logging.getLogger(__name__)
              
              HARBOR_URL = os.environ.get('HARBOR_URL', 'https://registry.{{ domain_name }}')
              HARBOR_USER = os.environ.get('HARBOR_USER', 'admin')
              HARBOR_PASSWORD = os.environ.get('HARBOR_PASSWORD', '')
              GITEA_URL = os.environ.get('GITEA_URL', 'https://git.{{ domain_name }}')
              GITEA_USER = os.environ.get('GITEA_USER', 'admin')
              GITEA_PASSWORD = os.environ.get('GITEA_PASSWORD', '')
              PORT = int(os.environ.get('PORT', '8080'))
              SYNC_WEBHOOK_URL = os.environ.get('SYNC_WEBHOOK_URL', '')
              SYNC_WEBHOOK_SECRET = os.environ.get('SYNC_WEBHOOK_SECRET', '')
              
              # CI/CD Monitoring configuration
              CICD_API_URL = os.environ.get('CICD_API_URL', 'https://control.thinkube.com/api/v1/cicd')
              CICD_API_TOKEN = os.environ.get('CICD_API_TOKEN', '')
              
              # Event sending removed - using stage-based approach only
              
              def create_cicd_stage(pipeline_id, stage_name, component, status='RUNNING', details=None, app_name=None, tag=None):
                  """Create a stage in CI/CD monitoring API using source-specific endpoints"""
                  if not CICD_API_TOKEN:
                      # During bootstrap, we can't create stages yet but will once token is available
                      return None
                  
                  try:
                      headers = {
                          'Authorization': f'Bearer {CICD_API_TOKEN}',
                          'Content-Type': 'application/json'
                      }
                      
                      # Use source-specific endpoints based on stage type
                      if stage_name == 'image_push' and component == 'harbor':
                          # Harbor webhook stage endpoint
                          stage_data = {
                              'stageName': 'image_push',
                              'component': 'harbor',
                              'appName': app_name or details.get('app_name', ''),
                              'tag': tag or details.get('tag', ''),
                              'backend': f'{HARBOR_URL.replace("https://", "")}/thinkube/{app_name}-backend:{tag}',
                              'frontend': f'{HARBOR_URL.replace("https://", "")}/thinkube/{app_name}-frontend:{tag}',
                              'adapterVersion': '0.2.0'
                          }
                          url = f"{CICD_API_URL}/pipelines/{pipeline_id}/stages/harbor"
                      elif stage_name == 'gitops_update' and component == 'webhook-adapter':
                          # GitOps update stage endpoint
                          stage_data = {
                              'stageName': 'gitops_update',
                              'component': 'webhook-adapter',
                              'appName': app_name or details.get('app_name', ''),
                              'tag': tag or details.get('tag', ''),
                              'status': status,
                              'adapterVersion': '0.2.0'
                          }
                          url = f"{CICD_API_URL}/pipelines/{pipeline_id}/stages/gitops"
                      else:
                          # Fallback - this shouldn't happen
                          logger.warning(f"Unknown stage type: {stage_name}/{component}")
                          return None
                      
                      response = requests.post(url, json=stage_data, headers=headers, timeout=5, verify=False)
                      
                      if response.status_code == 200:
                          stage_id = response.json().get('id')
                          logger.debug(f"Successfully created CI/CD stage: {stage_name} (ID: {stage_id})")
                          return stage_id
                      else:
                          logger.warning(f"Failed to create CI/CD stage: {response.status_code} - {response.text}")
                          return None
                          
                  except Exception as e:
                      # Don't let monitoring failures break the webhook processing
                      logger.warning(f"Error creating CI/CD stage: {e}")
                      return None
              
              def update_cicd_stage(pipeline_id, stage_id, status, error_message=None, details=None):
                  """Update a stage in CI/CD monitoring API"""
                  if not CICD_API_TOKEN:
                      logger.debug("CI/CD token not available yet - monitoring will auto-enable once thinkube-control creates it")
                      return
                  
                  try:
                      update_data = {
                          'status': status
                      }
                      
                      if status in ['SUCCEEDED', 'FAILED']:
                          update_data['completedAt'] = int(time.time())
                      
                      if error_message:
                          update_data['errorMessage'] = error_message
                      
                      if details:
                          update_data['details'] = details
                      
                      headers = {
                          'Authorization': f'Bearer {CICD_API_TOKEN}',
                          'Content-Type': 'application/json'
                      }
                      
                      # Use gitops-complete endpoint for stage updates
                      url = f"{CICD_API_URL}/pipelines/{pipeline_id}/stages/{stage_id}/gitops-complete?status={status}"
                      response = requests.put(url, headers=headers, timeout=5, verify=False)
                      
                      if response.status_code == 200:
                          logger.debug(f"Successfully updated CI/CD stage {stage_id} to {status}")
                      else:
                          logger.warning(f"Failed to update CI/CD stage: {response.status_code} - {response.text}")
                          
                  except Exception as e:
                      # Don't let monitoring failures break the webhook processing
                      logger.warning(f"Error updating CI/CD stage: {e}")
              
              def get_pipeline_by_workflow_uid(app_name, workflow_uid):
                  """Get pipeline ID by workflow UID (which matches the image tag)"""
                  if not CICD_API_TOKEN:
                      return None
                  
                  try:
                      headers = {
                          'Authorization': f'Bearer {CICD_API_TOKEN}',
                          'Content-Type': 'application/json'
                      }
                      
                      # Get pipelines for the application with the workflow UID
                      url = f"{CICD_API_URL}/pipelines?app_name={app_name}&workflow_uid={workflow_uid}&limit=1"
                      response = requests.get(url, headers=headers, timeout=5, verify=False)
                      
                      if response.status_code == 200:
                          data = response.json()
                          logger.debug(f"Pipeline API response type: {type(data)}, keys: {data.keys() if isinstance(data, dict) else 'not a dict'}")
                          # The response is wrapped in an object with 'pipelines' key
                          if isinstance(data, dict) and 'pipelines' in data:
                              pipelines = data.get('pipelines', [])
                              if pipelines and len(pipelines) > 0:
                                  pipeline_id = pipelines[0].get('id')
                                  logger.info(f"Found pipeline ID for {app_name}: {pipeline_id}")
                                  return pipeline_id
                              else:
                                  logger.warning(f"No pipelines found for {app_name} in response")
                                  return None
                          else:
                              logger.warning(f"Unexpected response format for {app_name}: {data}")
                              return None
                      
                      logger.warning(f"Could not get pipeline ID for {app_name}: HTTP {response.status_code}")
                      return None
                      
                  except Exception as e:
                      logger.warning(f"Error getting pipeline ID: {e}")
                      return None
              
              def get_app_metadata_from_workflow(workflow_uid):
                  """Get app metadata from Argo Workflow labels using the workflow UID (tag)"""
                  try:
                      # Use Kubernetes API to find workflow by UID
                      import urllib3
                      urllib3.disable_warnings()
                      
                      # Read service account token
                      token_path = '/var/run/secrets/kubernetes.io/serviceaccount/token'
                      if not os.path.exists(token_path):
                          raise Exception("Service account token not found")
                          
                      with open(token_path, 'r') as f:
                          token = f.read()
                      
                      headers = {'Authorization': f'Bearer {token}'}
                      
                      # Query all Argo workflows and filter by UID
                      # Note: fieldSelector doesn't support metadata.uid for CRDs
                      url = f'https://kubernetes.default.svc/apis/argoproj.io/v1alpha1/namespaces/argo/workflows'
                      response = requests.get(url, headers=headers, verify=False, timeout=5)
                      
                      if response.status_code == 200:
                          workflows = response.json().get('items', [])
                          # Find workflow by UID
                          matching_workflow = None
                          for wf in workflows:
                              if wf.get('metadata', {}).get('uid') == workflow_uid:
                                  matching_workflow = wf
                                  break
                          
                          if matching_workflow:
                              labels = matching_workflow.get('metadata', {}).get('labels', {})
                              app_name = labels.get('thinkube.io/app-name')
                              namespace = labels.get('thinkube.io/namespace')
                              
                              # For thinkube-control and other system apps, namespace might be empty
                              # Use the app namespace if not specified
                              if app_name:
                                  if not namespace:
                                      namespace = app_name  # Default to app name as namespace
                                  logger.info(f"Found workflow for app '{app_name}' in namespace '{namespace}'")
                                  return app_name, namespace
                              else:
                                  logger.warning(f"Workflow {workflow_uid} missing app-name label")
                                  return None, None
                          else:
                              logger.warning(f"No workflow found with UID {workflow_uid}")
                              return None, None
                      else:
                          logger.error(f"Failed to query workflows: {response.status_code}")
                          return None, None
                          
                  except Exception as e:
                      logger.error(f"Failed to get workflow metadata: {e}")
                      return None, None
              
              
              def check_harbor_image(project, repo, tag):
                  """Check if an image exists in Harbor registry"""
                  try:
                      url = f"{HARBOR_URL}/api/v2.0/projects/{project}/repositories/{repo}/artifacts/{tag}"
                      response = requests.get(url, auth=(HARBOR_USER, HARBOR_PASSWORD), verify=False, timeout=10)
                      return response.status_code == 200
                  except Exception as e:
                      logger.error(f"Failed to check Harbor image {project}/{repo}:{tag}: {e}")
                      return False
              
              def trigger_argocd_sync(app_name, pipeline_id=None):
                  """Trigger ArgoCD sync via sync webhook"""
                  if not SYNC_WEBHOOK_URL:
                      logger.info("Sync webhook URL not configured, skipping sync trigger")
                      return True
                  
                  try:
                      payload = {"application": app_name}
                      payload_json = json.dumps(payload)
                      headers = {"Content-Type": "application/json"}
                      
                      # Add HMAC signature if secret is configured
                      if SYNC_WEBHOOK_SECRET:
                          signature = hmac.new(
                              SYNC_WEBHOOK_SECRET.encode('utf-8'),
                              payload_json.encode('utf-8'),
                              hashlib.sha256
                          ).hexdigest()
                          headers["X-Webhook-Signature"] = signature
                      
                      response = requests.post(
                          SYNC_WEBHOOK_URL,
                          data=payload_json,
                          headers=headers,
                          timeout=30
                      )
                      
                      if response.status_code == 200:
                          logger.info(f"Successfully triggered sync for {app_name}")
                          return True
                      else:
                          logger.error(f"Failed to trigger sync for {app_name}: {response.status_code} - {response.text}")
                          return False
                          
                  except Exception as e:
                      logger.error(f"Error triggering sync: {e}")
                      return False
              
              def update_git_with_images(app_name, tag, containers, pipeline_id=None):
                  """Update git repository with new image tags"""
                  gitops_stage_id = None
                  try:
                      # Create GitOps update stage
                      if pipeline_id:
                          gitops_stage_id = create_cicd_stage(
                              pipeline_id, 'gitops_update', 'webhook-adapter',
                              status='RUNNING',
                              app_name=app_name, tag=tag
                          )
                      # Create temporary directory for git operations
                      with tempfile.TemporaryDirectory() as temp_dir:
                          repo_url = f"{GITEA_URL}/thinkube-deployments/{app_name}.git"
                          repo_dir = os.path.join(temp_dir, app_name)
                          
                          # Clone repository
                          clone_cmd = [
                              'git', 'clone', '--depth', '1', '--branch', 'main',
                              repo_url.replace('https://', f'https://{GITEA_USER}:{GITEA_PASSWORD}@'),
                              repo_dir
                          ]
                          result = subprocess.run(clone_cmd, capture_output=True, text=True, timeout=30)
                          if result.returncode != 0:
                              logger.error(f"Git clone failed: {result.stderr}")
                              
                              # Update GitOps stage as failed
                              if pipeline_id and gitops_stage_id:
                                  update_cicd_stage(pipeline_id, gitops_stage_id, 'FAILED',
                                                   error_message='Git clone failed')
                              
                              return False
                          
                          # Update .argocd-source file
                          argocd_file = os.path.join(repo_dir, 'k8s', f'.argocd-source-{app_name}.yaml')
                          
                          # Create/update the ArgoCD source file with new image tags
                          image_list = []
                          for container in containers:
                              image_list.append(f'{{ harbor_registry }}/thinkube/{app_name}-{container["name"]}:{tag}')
                          
                          # Write updated content
                          os.makedirs(os.path.dirname(argocd_file), exist_ok=True)
                          with open(argocd_file, 'w') as f:
                              # Write YAML manually to ensure correct format
                              f.write('kustomize:\n')
                              f.write('  images:\n')
                              for image in image_list:
                                  f.write(f'  - {image}\n')
                          
                          # Configure git user
                          subprocess.run(['git', 'config', 'user.name', 'harbor-webhook-adapter'], 
                                       cwd=repo_dir, timeout=10)
                          subprocess.run(['git', 'config', 'user.email', 'webhook@thinkube.com'], 
                                       cwd=repo_dir, timeout=10)
                          
                          # Commit changes
                          subprocess.run(['git', 'add', '.'], cwd=repo_dir, timeout=10)
                          commit_msg = f"build: automatic update of {app_name} to {tag}"
                          commit_result = subprocess.run(['git', 'commit', '-m', commit_msg], 
                                                       cwd=repo_dir, capture_output=True, text=True, timeout=10)
                          
                          if commit_result.returncode != 0:
                              if "nothing to commit" in commit_result.stdout:
                                  logger.info(f"No changes to commit for {app_name}:{tag}")
                                  
                                  # Update GitOps stage as succeeded (no changes needed)
                                  if pipeline_id and gitops_stage_id:
                                      update_cicd_stage(pipeline_id, gitops_stage_id, 'SUCCEEDED',
                                                       details={'app_name': app_name, 'tag': tag, 'note': 'No changes'})
                                  
                                  return True
                              else:
                                  logger.error(f"Git commit failed: {commit_result.stderr}")
                                  
                                  # Send GitOps update failed event
                                  if pipeline_id and gitops_stage_id:
                                      update_cicd_stage(pipeline_id, gitops_stage_id, 'FAILED', 
                                                       error_message='Git commit failed')
                                  
                                  return False
                          
                          # Push changes
                          push_result = subprocess.run(['git', 'push'], cwd=repo_dir, 
                                                     capture_output=True, text=True, timeout=30)
                          if push_result.returncode != 0:
                              logger.error(f"Git push failed: {push_result.stderr}")
                              
                              # Update GitOps stage as failed
                              if pipeline_id and gitops_stage_id:
                                  update_cicd_stage(pipeline_id, gitops_stage_id, 'FAILED',
                                                  error_message='Git push failed',
                                                  details={'app_name': app_name, 'tag': tag})
                              
                              return False
                          
                          logger.info(f"Successfully updated git for {app_name} with tag {tag}")
                          
                          # Update GitOps stage as succeeded
                          if pipeline_id and gitops_stage_id:
                              update_cicd_stage(pipeline_id, gitops_stage_id, 'SUCCEEDED',
                                              details={'app_name': app_name, 'tag': tag})
                          
                          # Trigger ArgoCD sync after Git update
                          if trigger_argocd_sync(app_name, pipeline_id):
                              logger.info(f"Successfully triggered ArgoCD sync for {app_name}")
                          else:
                              logger.warning(f"Failed to trigger ArgoCD sync for {app_name}, but Git update succeeded")
                          
                          return True
                          
                  except Exception as e:
                      logger.error(f"Failed to update git: {e}")
                      
                      # Update GitOps stage as failed due to error
                      if pipeline_id and gitops_stage_id:
                          update_cicd_stage(pipeline_id, gitops_stage_id, 'FAILED',
                                          error_message=str(e),
                                          details={'app_name': app_name, 'tag': tag})
                      
                      return False
              
              def process_webhook_async(webhook_data):
                  """Process webhook in background thread"""
                  try:
                      logger.info(f"Background processing started for webhook: {webhook_data.get('type', 'unknown')}")
                      
                      # Process only PUSH_ARTIFACT events
                      if webhook_data.get('type') == 'PUSH_ARTIFACT':
                          event_data = webhook_data.get('event_data', {})
                          repository = event_data.get('repository', {})
                          resources = event_data.get('resources', [])
                          
                          if repository and resources:
                              repo_name = repository.get('repo_full_name', '')
                              logger.info(f"Webhook for repo {repo_name} with {len(resources)} resources")
                              
                              # Initialize variables
                              app_name = None
                              namespace = None
                              workflow_uid = None
                              
                              # Find the workflow UID from the resources (it's the tag)
                              for resource in resources:
                                  tag = resource.get('tag', '')
                                  if tag and tag != 'latest':  # The tag is the workflow UID
                                      workflow_uid = tag
                                      break
                              
                              if not workflow_uid:
                                  logger.warning("No workflow UID found in webhook resources")
                                  return
                              
                              # Get app metadata from the workflow
                              app_name, namespace = get_app_metadata_from_workflow(workflow_uid)
                              
                              if not app_name or not namespace:
                                  logger.error(f"Failed to find workflow metadata for UID: {workflow_uid}")
                                  return
                              
                              # Get container information from the workflow template
                              # The workflow knows which containers it's building
                              containers = []
                              
                              # Read service account token
                              token_path = '/var/run/secrets/kubernetes.io/serviceaccount/token'
                              with open(token_path, 'r') as f:
                                  token = f.read()
                              
                              headers = {'Authorization': f'Bearer {token}'}
                              
                              # Get the WorkflowTemplate to see which containers it builds
                              wft_url = f'https://kubernetes.default.svc/apis/argoproj.io/v1alpha1/namespaces/argo/workflowtemplates/{app_name}-build'
                              wft_response = requests.get(wft_url, headers=headers, verify=False, timeout=5)
                              
                              if wft_response.status_code != 200:
                                  logger.error(f"Failed to get WorkflowTemplate: {wft_response.status_code}")
                                  return
                              
                              wft_data = wft_response.json()
                              spec = wft_data.get('spec', {})
                              templates = spec.get('templates', [])
                              
                              # Find build tasks to identify containers
                              for template in templates:
                                  # Check for both template names used by different apps
                                  if template.get('name') in ['ci-cd-pipeline', 'build-and-push']:
                                      dag = template.get('dag', {})
                                      tasks = dag.get('tasks', [])
                                      for task in tasks:
                                          task_name = task.get('name', '')
                                          # Skip non-build tasks
                                          if task_name.startswith('build-') and task_name not in ['build-pipeline', 'build-and-push']:
                                              container_name = task_name.replace('build-', '')
                                              containers.append({'name': container_name})
                              
                              if not containers:
                                  logger.error(f"No container build tasks found in WorkflowTemplate for {app_name}")
                                  return
                              
                              logger.info(f"Found {len(containers)} containers from WorkflowTemplate: {[c['name'] for c in containers]}")
                              # Initialize pipeline_id as None - will be set when we find the matching tag
                              pipeline_id = None
                              
                              for resource in resources:
                                  tag = resource.get('tag', '')
                                  if tag and tag != 'latest':  # Ignore latest tags
                                      logger.info(f"Received webhook for {app_name} - {repo_name}:{tag}")
                                      
                                      # Smart Detection: Check if all container images exist in Harbor
                                      try:
                                          # Use containers from metadata we already retrieved
                                          container_names = [c['name'] for c in containers]
                                          
                                          # Check each container image
                                          image_status = {}
                                          for container in containers:
                                              container_name = container['name']
                                              exists = check_harbor_image('thinkube', f'{app_name}-{container_name}', tag)
                                              image_status[container_name] = exists
                                          
                                          all_images_exist = all(image_status.values())
                                          logger.info(f"Image check for {app_name}:{tag} - {image_status}")
                                          
                                          if all_images_exist:
                                              logger.info(f"All {len(containers)} images found for {app_name}:{tag}, checking if already processed...")
                                              
                                              # Get pipeline ID using the tag (which is the workflow UID)
                                              pipeline_id = get_pipeline_by_workflow_uid(app_name, tag)
                                              if not pipeline_id:
                                                  logger.warning(f"No pipeline found for {app_name} with workflow UID {tag}, processing without monitoring")
                                              else:
                                                  logger.info(f"Found pipeline ID {pipeline_id} for {app_name} with tag/workflow UID {tag}")
                                              
                                              # Check if we've already processed this tag (either image_push OR gitops_update exists)
                                              if pipeline_id and CICD_API_TOKEN:
                                                  already_processed = False
                                                  try:
                                                      headers = {
                                                          'Authorization': f'Bearer {CICD_API_TOKEN}',
                                                          'Content-Type': 'application/json'
                                                      }
                                                      stages_url = f"{CICD_API_URL}/pipelines/{pipeline_id}"
                                                      stages_response = requests.get(stages_url, headers=headers, timeout=5, verify=False)
                                                      if stages_response.status_code == 200:
                                                          pipeline_data = stages_response.json()
                                                          # Check for either image_push or gitops_update with this tag
                                                          for stage in pipeline_data.get('stages', []):
                                                              if stage['stageName'] in ['image_push', 'gitops_update']:
                                                                  if stage.get('details', {}).get('tag') == tag:
                                                                      already_processed = True
                                                                      logger.info(f"Tag {tag} already processed (found {stage['stageName']} stage)")
                                                                      break
                                                  except Exception as e:
                                                      logger.warning(f"Error checking existing stages: {e}")
                                                  
                                                  if not already_processed:
                                                      image_push_stage = create_cicd_stage(
                                                          pipeline_id, 'image_push', 'harbor',
                                                          status='SUCCEEDED',
                                                          app_name=app_name, tag=tag
                                                      )
                                                      if not image_push_stage:
                                                          logger.error(f"Failed to create image_push stage for {app_name}:{tag}, skipping git update")
                                                          continue
                                              
                                              # Update git repository with both image tags
                                              if update_git_with_images(app_name, tag, containers, pipeline_id):
                                                  logger.info(f"Successfully updated git for {app_name}:{tag}")
                                              else:
                                                  logger.error(f"Failed to update git for {app_name}:{tag}")
                                          else:
                                              missing_containers = [name for name, exists in image_status.items() if not exists]
                                              logger.info(f"Waiting for images: {missing_containers}")
                                              
                                      except Exception as e:
                                          logger.error(f"Failed to process webhook for {app_name}:{tag}: {e}")
                      
                      logger.info("Background processing completed")
                      
                  except Exception as e:
                      logger.error(f"Error in background webhook processing: {e}")
                      import traceback
                      logger.error(traceback.format_exc())
              
              class WebhookHandler(BaseHTTPRequestHandler):
                  def do_GET(self):
                      # Health check endpoint
                      if self.path == '/' or self.path == '/health':
                          self.send_response(200)
                          self.send_header('Content-type', 'application/json')
                          self.end_headers()
                          self.wfile.write(json.dumps({"status": "ok"}).encode())
                      else:
                          self.send_response(404)
                          self.end_headers()
                  
                  def do_POST(self):
                      if self.path != '/webhook':
                          self.send_response(404)
                          self.end_headers()
                          return
                      
                      try:
                          content_length = int(self.headers['Content-Length'])
                          post_data = self.rfile.read(content_length)
                          webhook_data = json.loads(post_data)
                          
                          # Log the webhook for debugging
                          logger.info(f"Received webhook: {webhook_data.get('type', 'unknown')}")
                          
                          # Start processing in background thread
                          thread = threading.Thread(target=process_webhook_async, args=(webhook_data,))
                          thread.daemon = True  # Don't wait for thread to complete on shutdown
                          thread.start()
                          
                          # Immediately respond to Harbor
                          self.send_response(200)
                          self.send_header('Content-type', 'application/json')
                          self.end_headers()
                          self.wfile.write(json.dumps({"status": "accepted"}).encode())
                          
                      except Exception as e:
                          logger.error(f"Error receiving webhook: {e}")
                          self.send_response(500)
                          self.end_headers()
                          self.wfile.write(json.dumps({"error": str(e)}).encode())
                  
                  def log_message(self, format, *args):
                      # Suppress default access logs
                      pass
              
              if __name__ == '__main__':
                  try:
                      logger.info(f"Starting webhook adapter on port {PORT}")
                      logger.info(f"Harbor URL: {HARBOR_URL}")
                      logger.info(f"Gitea URL: {GITEA_URL}")
                      logger.info(f"CI/CD API URL: {CICD_API_URL}")
                      logger.info(f"CI/CD monitoring enabled: {'Yes' if CICD_API_TOKEN else 'No'}")
                      if not CICD_API_TOKEN:
                          logger.info("Running in bootstrap mode - webhook processing active, CI/CD monitoring will auto-enable when token becomes available")
                      
                      # Add debug logging
                      logger.info(f"Creating HTTP server on 0.0.0.0:{PORT}")
                      httpd = HTTPServer(('0.0.0.0', PORT), WebhookHandler)
                      logger.info("HTTP server created successfully, starting to serve...")
                      httpd.serve_forever()
                  except Exception as e:
                      logger.error(f"Failed to start webhook adapter: {e}")
                      import traceback
                      logger.error(traceback.format_exc())
                      sys.exit(1)

    - name: Create ServiceAccount for webhook adapter
      kubernetes.core.k8s:
        kubeconfig: "{{ kubeconfig }}"
        state: present
        definition:
          apiVersion: v1
          kind: ServiceAccount
          metadata:
            name: "{{ adapter_name }}"
            namespace: "{{ adapter_namespace }}"

    - name: Create ClusterRole for ConfigMap reading
      kubernetes.core.k8s:
        kubeconfig: "{{ kubeconfig }}"
        state: present
        definition:
          apiVersion: rbac.authorization.k8s.io/v1
          kind: ClusterRole
          metadata:
            name: "{{ adapter_name }}-configmap-reader"
          rules:
          - apiGroups: [""]
            resources: ["configmaps"]
            verbs: ["get", "list"]

    - name: Create ClusterRoleBinding
      kubernetes.core.k8s:
        kubeconfig: "{{ kubeconfig }}"
        state: present
        definition:
          apiVersion: rbac.authorization.k8s.io/v1
          kind: ClusterRoleBinding
          metadata:
            name: "{{ adapter_name }}-configmap-reader"
          roleRef:
            apiGroup: rbac.authorization.k8s.io
            kind: ClusterRole
            name: "{{ adapter_name }}-configmap-reader"
          subjects:
          - kind: ServiceAccount
            name: "{{ adapter_name }}"
            namespace: "{{ adapter_namespace }}"

    - name: Deploy webhook adapter
      kubernetes.core.k8s:
        kubeconfig: "{{ kubeconfig }}"
        state: present
        definition:
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            name: "{{ adapter_name }}"
            namespace: "{{ adapter_namespace }}"
          spec:
            replicas: 1
            selector:
              matchLabels:
                app: "{{ adapter_name }}"
            template:
              metadata:
                labels:
                  app: "{{ adapter_name }}"
              spec:
                serviceAccountName: "{{ adapter_name }}"
                containers:
                - name: adapter
                  image: "{{ harbor_registry }}/library/python:3.12-alpine"
                  command: ["/bin/sh", "-c"]
                  args: ["apk add --no-cache git && pip install --no-cache-dir requests pyyaml && python -u /app/adapter.py"]
                  env:
                  - name: HARBOR_URL
                    value: "https://registry.{{ domain_name }}"
                  - name: HARBOR_USER
                    value: "admin"
                  - name: HARBOR_PASSWORD
                    value: "{{ lookup('env', 'ADMIN_PASSWORD') | default(lookup('env', 'ANSIBLE_BECOME_PASSWORD'), true) }}"
                  - name: GITEA_URL
                    value: "https://git.{{ domain_name }}"
                  - name: GITEA_USER
                    value: "{{ admin_username }}"
                  - name: GITEA_PASSWORD
                    value: "{{ lookup('env', 'ADMIN_PASSWORD') | default(lookup('env', 'ANSIBLE_BECOME_PASSWORD'), true) }}"
                  - name: PORT
                    value: "8080"
                  - name: SYNC_WEBHOOK_URL
                    value: "http://argocd-sync-webhook.{{ adapter_namespace }}.svc.cluster.local/sync"
                  - name: SYNC_WEBHOOK_SECRET
                    value: "{{ sync_webhook_secret | default('') }}"
                  - name: CICD_API_URL
                    value: "https://control.{{ domain_name }}/api/v1/cicd"
                  - name: CICD_API_TOKEN
                    value: "{{ cicd_monitoring_token | default('') }}"
                  ports:
                  - containerPort: 8080
                    name: http
                  resources:
                    requests:
                      cpu: 50m
                      memory: 64Mi
                    limits:
                      cpu: 100m
                      memory: 128Mi
                  livenessProbe:
                    httpGet:
                      path: /
                      port: 8080
                    initialDelaySeconds: 10
                    periodSeconds: 30
                  readinessProbe:
                    httpGet:
                      path: /
                      port: 8080
                    initialDelaySeconds: 5
                    periodSeconds: 10
                  volumeMounts:
                  - name: script
                    mountPath: /app
                volumes:
                - name: script
                  configMap:
                    name: "{{ adapter_name }}-script"

    - name: Create Service for webhook adapter
      kubernetes.core.k8s:
        kubeconfig: "{{ kubeconfig }}"
        state: present
        definition:
          apiVersion: v1
          kind: Service
          metadata:
            name: "{{ adapter_name }}"
            namespace: "{{ adapter_namespace }}"
          spec:
            selector:
              app: "{{ adapter_name }}"
            ports:
            - port: 80
              targetPort: 8080
              name: http

    - name: Create Ingress for webhook adapter
      kubernetes.core.k8s:
        kubeconfig: "{{ kubeconfig }}"
        state: present
        definition:
          apiVersion: networking.k8s.io/v1
          kind: Ingress
          metadata:
            name: "{{ adapter_name }}"
            namespace: "{{ adapter_namespace }}"
            annotations:
              nginx.ingress.kubernetes.io/ssl-redirect: "true"
          spec:
            ingressClassName: nginx
            tls:
            - hosts:
              - "{{ adapter_name }}.{{ domain_name }}"
              secretName: "{{ adapter_namespace }}-tls-secret"
            rules:
            - host: "{{ adapter_name }}.{{ domain_name }}"
              http:
                paths:
                - path: /
                  pathType: Prefix
                  backend:
                    service:
                      name: "{{ adapter_name }}"
                      port:
                        number: 80

    - name: Wait for deployment to be ready
      kubernetes.core.k8s_info:
        kubeconfig: "{{ kubeconfig }}"
        api_version: apps/v1
        kind: Deployment
        namespace: "{{ adapter_namespace }}"
        name: "{{ adapter_name }}"
        wait: true
        wait_condition:
          type: Progressing
          status: "True"
        wait_timeout: 300

    - name: Restart webhook adapter pods
      kubernetes.core.k8s:
        kubeconfig: "{{ kubeconfig }}"
        state: present
        definition:
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            name: "{{ adapter_name }}"
            namespace: "{{ adapter_namespace }}"
          spec:
            template:
              metadata:
                annotations:
                  restartedAt: "{{ ansible_date_time.iso8601 }}"

    - name: Get admin password from environment
      ansible.builtin.set_fact:
        admin_password: "{{ lookup('env', 'ADMIN_PASSWORD') | default(lookup('env', 'ANSIBLE_BECOME_PASSWORD'), true) }}"
      when: admin_password is not defined
      delegate_to: localhost
    
    - name: Debug admin credentials
      ansible.builtin.debug:
        msg: 
          - "Using admin username: {{ admin_username }}"
          - "Using admin password: {{ admin_password | length }} characters"
          - "Harbor URL: https://{{ harbor_registry }}/api/v2.0/projects/{{ harbor_project }}/webhook/policies"

    - name: Configure Harbor webhook for thinkube project
      when: not (skip_webhook_config | default(false))
      ansible.builtin.uri:
        url: "https://{{ harbor_registry }}/api/v2.0/projects/{{ harbor_project }}/webhook/policies"
        method: POST
        validate_certs: false
        headers:
          Authorization: "Basic {{ ('admin:' + admin_password) | b64encode }}"
          Content-Type: "application/json"
        body_format: json
        body:
          name: "ArgoCD Git Updater"
          description: "Update Git repository on image push"
          enabled: true
          targets:
            - type: "http"
              address: "https://{{ adapter_name }}.{{ domain_name }}/webhook"
              skip_cert_verify: true
          event_types:
            - "PUSH_ARTIFACT"
      register: webhook_create
      failed_when: webhook_create.status not in [201, 409]
      changed_when: webhook_create.status == 201

    - name: Check if webhook already exists
      ansible.builtin.debug:
        msg: "Harbor webhook already configured"
      when: 
        - not (skip_webhook_config | default(false))
        - webhook_create.status == 409

    - name: Verify webhook secret consistency
      ansible.builtin.debug:
        msg: |
          Webhook adapter using secret: {{ sync_webhook_secret | default('NOT SET') }}
          Secret length: {{ sync_webhook_secret | length if sync_webhook_secret else 0 }} characters
      when: sync_webhook_secret is defined

    - name: Display webhook adapter status
      ansible.builtin.debug:
        msg: |
          
          ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
          ‚úÖ Harbor Webhook Adapter Deployed Successfully
          ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
          
          Adapter URL: https://{{ adapter_name }}.{{ domain_name }}/webhook
          Sync Webhook Secret: {{ 'Configured (' + (sync_webhook_secret | length | string) + ' chars)' if sync_webhook_secret else 'Not configured' }}
          
          The CI/CD pipeline is now optimized for instant deployment:
          1. Push code ‚Üí Build (~1 min)
          2. Harbor webhook ‚Üí Git update (instant)
          3. Git commit ‚Üí ArgoCD webhook (instant)
          4. ArgoCD deploys (30 sec)
          
          Total time: ~1.5 minutes (from push to deployment)
          
          CI/CD Monitoring Integration:
          - harbor_webhook_received: When webhook is received
          - gitops_update_started: When starting to update Git
          - gitops_update_completed: When Git push succeeds
          - argocd_sync_triggered: When ArgoCD sync is triggered
          
          This provides a near-local development experience!
          ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê