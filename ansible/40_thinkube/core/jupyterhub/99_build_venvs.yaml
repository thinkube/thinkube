# Copyright 2025 Alejandro Martínez Corriá and the Thinkube contributors
# SPDX-License-Identifier: Apache-2.0
#
# ansible/40_thinkube/core/jupyterhub/99_build_venvs.yaml
#
# PURPOSE:
#   Build pre-packaged Python virtualenvs for JupyterHub and upload to GitHub.
#   Fully automated - waits for build completion and uploads to GitHub releases.
#
# REQUIREMENTS:
#   - tk-jupyter-base image built and pushed to Harbor
#   - kubectl access to the cluster
#   - GPU node available for the target architecture
#   - gh CLI authenticated (gh auth login)
#
# NOTE: This playbook is self-contained. It creates its own temporary PVC
#       for the build and cleans it up afterward. No dependency on 11_deploy.yaml.
#
# USAGE:
#   ./scripts/tk_ansible ansible/40_thinkube/core/jupyterhub/99_build_venvs.yaml
#
# OUTPUT:
#   Venv tarballs uploaded to GitHub release at:
#   https://github.com/thinkube/thinkube-venvs/releases/tag/{version}

---
- name: Build and Upload Jupyter Virtualenvs
  hosts: k8s_control_plane
  gather_facts: true

  vars:
    venvs_version: "v0.1.0"
    build_namespace: "jupyterhub"
    job_name: "venvs-builder"
    build_pvc_name: "venvs-build-temp"
    github_repo: "thinkube/thinkube-venvs"
    local_output_dir: "/tmp/venvs-output-{{ ansible_date_time.epoch | default(lookup('pipe', 'date +%s')) }}"

  tasks:
    - name: Ensure namespace exists
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: v1
          kind: Namespace
          metadata:
            name: "{{ build_namespace }}"

    - name: Create temporary PVC for build output
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: v1
          kind: PersistentVolumeClaim
          metadata:
            name: "{{ build_pvc_name }}"
            namespace: "{{ build_namespace }}"
          spec:
            accessModes:
              - ReadWriteOnce
            storageClassName: csi-rawfile-default
            resources:
              requests:
                storage: 50Gi

    - name: Display build info
      ansible.builtin.debug:
        msg: |
          ════════════════════════════════════════════════════════════════
          Building Jupyter Venvs {{ venvs_version }}
          ════════════════════════════════════════════════════════════════

          This playbook will:
          1. Build venvs in a K8s Job (20-40 minutes)
          2. Copy tarballs to local filesystem
          3. Upload to GitHub release automatically

          GitHub repo: {{ github_repo }}

    - name: Check gh CLI is authenticated
      ansible.builtin.command: gh auth status
      register: gh_auth
      failed_when: gh_auth.rc != 0
      changed_when: false
      delegate_to: localhost

    - name: Check if GitHub repo exists
      ansible.builtin.command: gh repo view {{ github_repo }}
      register: repo_check
      failed_when: false
      changed_when: false
      delegate_to: localhost

    - name: Create GitHub repo if it doesn't exist
      ansible.builtin.command: >
        gh repo create {{ github_repo }}
        --public
        --description "Pre-built Python virtualenvs for Thinkube JupyterHub"
      when: repo_check.rc != 0
      delegate_to: localhost

    - name: Check if repo has commits (releases require non-empty repo)
      ansible.builtin.shell: |
        result=$(gh api repos/{{ github_repo }}/commits --jq 'length' 2>&1)
        if echo "$result" | grep -q "empty"; then
          echo "empty"
        else
          echo "$result"
        fi
      register: repo_commits
      failed_when: false
      changed_when: false
      delegate_to: localhost

    - name: Initialize repo with README (required for releases)
      ansible.builtin.shell: |
        set -e
        cd /tmp && rm -rf thinkube-venvs
        git clone git@github.com:{{ github_repo }}.git thinkube-venvs
        cd thinkube-venvs
        echo "# Thinkube Venvs" > README.md
        echo "" >> README.md
        echo "Pre-built Python virtualenvs for Thinkube JupyterHub." >> README.md
        git add README.md
        git commit -m "Initial commit"
        git push origin main
        cd /tmp && rm -rf thinkube-venvs
      when: repo_commits.stdout | trim == "empty"
      delegate_to: localhost

    - name: Copy build script to ConfigMap
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: venvs-build-script
            namespace: "{{ build_namespace }}"
          data:
            build-venvs.sh: |
              {{ lookup('file', playbook_dir + '/scripts/build-venvs.sh') | indent(14) }}

    - name: Delete existing build job if present
      kubernetes.core.k8s:
        state: absent
        api_version: batch/v1
        kind: Job
        name: "{{ job_name }}"
        namespace: "{{ build_namespace }}"
        wait: true
        wait_timeout: 60
      ignore_errors: true

    - name: Create venvs build job
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: batch/v1
          kind: Job
          metadata:
            name: "{{ job_name }}"
            namespace: "{{ build_namespace }}"
          spec:
            ttlSecondsAfterFinished: 3600  # Keep for 1 hour after completion
            backoffLimit: 0  # Don't retry on failure
            template:
              spec:
                restartPolicy: Never
                # Init container to fix PVC permissions for thinkube user (UID 1000)
                initContainers:
                  - name: fix-permissions
                    image: "{{ harbor_registry }}/library/busybox:latest"
                    command: ["sh", "-c", "chown -R 1000:100 /output"]
                    securityContext:
                      runAsUser: 0
                    volumeMounts:
                      - name: output
                        mountPath: /output
                containers:
                  - name: builder
                    image: "{{ harbor_registry }}/library/tk-jupyter-base:latest"
                    imagePullPolicy: Always
                    command:
                      - bash
                      - /scripts/build-venvs.sh
                    env:
                      - name: VENVS_VERSION
                        value: "{{ venvs_version }}"
                      - name: OUTPUT_DIR
                        value: /output
                    volumeMounts:
                      - name: build-script
                        mountPath: /scripts
                      - name: output
                        mountPath: /output
                    resources:
                      requests:
                        memory: "8Gi"
                        cpu: "2"
                      limits:
                        memory: "16Gi"
                        cpu: "4"
                volumes:
                  - name: build-script
                    configMap:
                      name: venvs-build-script
                      defaultMode: 0755
                  # Use temporary PVC for build output (survives pod completion)
                  - name: output
                    persistentVolumeClaim:
                      claimName: "{{ build_pvc_name }}"
                # Schedule on GPU nodes to get correct architecture
                nodeSelector:
                  nvidia.com/gpu.present: "true"

    - name: Wait for build job to complete (this takes 20-40 minutes)
      kubernetes.core.k8s_info:
        api_version: batch/v1
        kind: Job
        name: "{{ job_name }}"
        namespace: "{{ build_namespace }}"
      register: job_info
      until: >
        (job_info.resources[0].status.succeeded is defined and job_info.resources[0].status.succeeded == 1) or
        (job_info.resources[0].status.failed is defined and job_info.resources[0].status.failed > 0)
      retries: 180  # 180 * 20s = 60 minutes max wait
      delay: 20

    - name: Check if build succeeded
      ansible.builtin.fail:
        msg: "Venvs build job failed! Check logs with: kubectl logs job/{{ job_name }} -n {{ build_namespace }}"
      when: job_info.resources[0].status.failed is defined and job_info.resources[0].status.failed > 0

    # Use a helper pod to copy files from PVC since kubectl cp requires running pod
    - name: Create helper pod to copy tarballs
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: v1
          kind: Pod
          metadata:
            name: venvs-copy-helper
            namespace: "{{ build_namespace }}"
          spec:
            restartPolicy: Never
            containers:
              - name: helper
                image: "{{ harbor_registry }}/library/busybox:latest"
                command: ["sleep", "3600"]
                volumeMounts:
                  - name: venvs
                    mountPath: /venvs
            volumes:
              - name: venvs
                persistentVolumeClaim:
                  claimName: "{{ build_pvc_name }}"
            nodeSelector:
              nvidia.com/gpu.present: "true"

    - name: Wait for helper pod to be ready
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Pod
        name: venvs-copy-helper
        namespace: "{{ build_namespace }}"
      register: helper_pod
      until: helper_pod.resources[0].status.phase == "Running"
      retries: 30
      delay: 5

    - name: Create local output directory
      ansible.builtin.file:
        path: "{{ local_output_dir }}"
        state: directory
        mode: '0755'
      delegate_to: localhost

    - name: Copy tarballs from helper pod
      ansible.builtin.shell: |
        export KUBECONFIG=$HOME/.kube/config
        # List available tarballs first
        kubectl exec -n {{ build_namespace }} venvs-copy-helper -- ls -la /venvs/arm64/
        # Copy each tarball directly
        kubectl cp {{ build_namespace }}/venvs-copy-helper:/venvs/arm64/fine-tuning.tar.gz {{ local_output_dir }}/fine-tuning.tar.gz
        kubectl cp {{ build_namespace }}/venvs-copy-helper:/venvs/arm64/agent-dev.tar.gz {{ local_output_dir }}/agent-dev.tar.gz
        ls -la {{ local_output_dir }}/
      delegate_to: localhost

    - name: Delete helper pod
      kubernetes.core.k8s:
        state: absent
        api_version: v1
        kind: Pod
        name: venvs-copy-helper
        namespace: "{{ build_namespace }}"

    - name: List downloaded tarballs
      ansible.builtin.find:
        paths: "{{ local_output_dir }}"
        patterns: "*.tar.gz"
        recurse: true
      register: tarballs
      delegate_to: localhost

    - name: Display tarballs found
      ansible.builtin.debug:
        msg: "Found {{ tarballs.files | length }} tarballs: {{ tarballs.files | map(attribute='path') | list }}"

    - name: Check if GitHub release already exists
      ansible.builtin.command: gh release view {{ venvs_version }} --repo {{ github_repo }}
      register: release_exists
      failed_when: false
      changed_when: false
      delegate_to: localhost

    - name: Create GitHub release (if it doesn't exist)
      ansible.builtin.shell: |
        gh release create {{ venvs_version }} \
          --repo {{ github_repo }} \
          --title "Jupyter Venvs {{ venvs_version }}" \
          --notes "Pre-built Python virtualenvs for JupyterHub.

        These venvs inherit PyTorch from the tk-jupyter-base image via --system-site-packages.

        Venvs included:
        - **fine-tuning**: Base ML + fine-tuning packages (bitsandbytes, peft, trl, unsloth)
        - **agent-dev**: Base ML + agent frameworks (langchain, crewai, langgraph, etc.)

        Architecture: arm64 (DGX Spark GB10)"
      when: release_exists.rc != 0
      delegate_to: localhost

    - name: Upload tarballs to GitHub release
      ansible.builtin.command: >
        gh release upload {{ venvs_version }} {{ item.path }}
        --repo {{ github_repo }}
        --clobber
      loop: "{{ tarballs.files }}"
      loop_control:
        label: "{{ item.path | basename }}"
      delegate_to: localhost

    - name: Clean up local output directory
      ansible.builtin.file:
        path: "{{ local_output_dir }}"
        state: absent
      delegate_to: localhost

    - name: Delete build job
      kubernetes.core.k8s:
        state: absent
        api_version: batch/v1
        kind: Job
        name: "{{ job_name }}"
        namespace: "{{ build_namespace }}"

    - name: Delete temporary build PVC
      kubernetes.core.k8s:
        state: absent
        api_version: v1
        kind: PersistentVolumeClaim
        name: "{{ build_pvc_name }}"
        namespace: "{{ build_namespace }}"

    - name: Display completion message
      ansible.builtin.debug:
        msg: |

          ════════════════════════════════════════════════════════════════
          Venvs Build and Upload Complete!
          ════════════════════════════════════════════════════════════════

          Version: {{ venvs_version }}
          GitHub Release: https://github.com/{{ github_repo }}/releases/tag/{{ venvs_version }}

          Uploaded tarballs:
          {% for tarball in tarballs.files %}
            - {{ tarball.path | basename }}
          {% endfor %}

          JupyterHub pods will automatically download these venvs on startup.

          ════════════════════════════════════════════════════════════════
