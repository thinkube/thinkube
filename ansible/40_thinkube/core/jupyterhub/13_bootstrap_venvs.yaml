# Copyright 2025 Alejandro Martínez Corriá and the Thinkube contributors
# SPDX-License-Identifier: Apache-2.0
#
# ansible/40_thinkube/core/jupyterhub/13_bootstrap_venvs.yaml
#
# PURPOSE:
#   Bootstrap persistent virtualenvs on JuiceFS for Jupyter kernels.
#   Run this playbook on each GPU node architecture (ARM64, x86_64) to create
#   architecture-specific venvs with ML packages.
#
# REQUIREMENTS:
#   - JupyterHub deployed (11_deploy.yaml) with venvs PVC created
#   - JuiceFS mount available on the target node
#   - GPU node with Python 3.12+ and CUDA support
#
# USAGE:
#   # Bootstrap venvs on DGX Spark (ARM64):
#   ./scripts/tk_ansible ansible/40_thinkube/core/jupyterhub/13_bootstrap_venvs.yaml -l tkspark
#
#   # Future: Bootstrap venvs on x86_64 GPU node:
#   ./scripts/tk_ansible ansible/40_thinkube/core/jupyterhub/13_bootstrap_venvs.yaml -l gpu-workstation

---
- name: Bootstrap Jupyter Virtualenvs
  hosts: gpu_nodes
  become: true
  gather_facts: true

  vars:
    # JuiceFS mount point for venvs PVC
    # This should match where JuiceFS CSI mounts the jupyterhub-venvs-pvc
    juicefs_mount: "/var/lib/juicefs/volumes"
    venvs_pvc_name: "jupyterhub-venvs-pvc"

    # Architecture detection
    arch_name: "{{ 'arm64' if ansible_architecture == 'aarch64' else 'amd64' }}"

    # Python version (NVIDIA PyTorch 25.04 uses Python 3.12)
    python_cmd: "python3.12"

    # Package lists matching current Jupyter images
    ml_gpu_packages:
      - ipykernel
      - transformers==4.56.2
      - datasets==4.1.1
      - accelerate==1.10.1
      - nvidia-modelopt
      - pandas==2.3.2
      - scikit-learn==1.7.2
      - matplotlib==3.10.6
      - seaborn==0.13.2
      - plotly==6.3.0
      - psycopg2-binary==2.9.10
      - redis==6.4.0
      - qdrant-client==1.15.1
      - opensearch-py==3.0.0
      - mlflow==3.4.0
      - boto3==1.40.40
      - clickhouse-connect
      - chromadb
      - nats-py
      - weaviate-client==4.17.0
      - litellm==1.74.9
      - kubernetes
      - PyGithub
      - hera-workflows
      - argilla
      - cvat-sdk
      - langfuse
      - openai
      - arxiv
      - python-dotenv==1.1.1
      - requests==2.32.5
      - httpx==0.28.1
      - pydantic==2.11.9
      - sqlalchemy
      - alembic
      - ipywidgets
      - jupyterlab-widgets
      - tqdm
      - Pillow
      - opencv-python
      - sentence-transformers
      - spacy
      - grpcio
      - grpcio-tools
      - gql
      - websockets
      - claude-agent-sdk
      - openai-harmony

    fine_tuning_packages:
      - ipykernel
      - bitsandbytes>=0.48.2
      - peft>=0.17.1
      - trl==0.23.0
      - tyro
      - hf_transfer
      - sentencepiece
      - protobuf
      - openpyxl
      - nvidia-modelopt

    agent_dev_packages:
      - ipykernel
      - langchain==1.1.3
      - langchain-core==1.1.3
      - langchain-community==0.4.1
      - langchain-openai==1.1.1
      - "ag2[openai]==0.10.2"
      - langgraph==0.4.1
      - openai-agents==0.6.2
      - crewai==1.7.0
      - crewai-tools==1.7.0
      - faiss-cpu==1.12.0
      - opentelemetry-sdk==1.39.0
      - opentelemetry-exporter-otlp==1.39.0
      - opentelemetry-api==1.39.0
      - tiktoken

  tasks:
    - name: Display bootstrap info
      ansible.builtin.debug:
        msg: |
          Bootstrapping Jupyter venvs for {{ arch_name }}
          Host: {{ inventory_hostname }}
          Python: {{ python_cmd }}

    # Find the JuiceFS mount for the venvs PVC
    - name: Find JuiceFS venvs mount
      ansible.builtin.shell: |
        # Find where JuiceFS mounted the venvs PVC
        mount | grep juicefs | grep -E "jupyterhub.*venvs|pvc-.*venvs" | awk '{print $3}' | head -1
      register: venvs_mount_result
      changed_when: false
      failed_when: false

    - name: Set venvs base path
      ansible.builtin.set_fact:
        venvs_base: "{{ venvs_mount_result.stdout | default('/mnt/juicefs/jupyterhub-venvs') }}"

    - name: Display venvs path
      ansible.builtin.debug:
        msg: "Venvs base path: {{ venvs_base }}"

    # Create architecture directory
    - name: Create architecture directory
      ansible.builtin.file:
        path: "{{ venvs_base }}/{{ arch_name }}"
        state: directory
        mode: "0755"

    # Check if venvs already exist
    - name: Check if ml-gpu venv exists
      ansible.builtin.stat:
        path: "{{ venvs_base }}/{{ arch_name }}/ml-gpu/bin/python"
      register: ml_gpu_exists

    - name: Check if fine-tuning venv exists
      ansible.builtin.stat:
        path: "{{ venvs_base }}/{{ arch_name }}/fine-tuning/bin/python"
      register: fine_tuning_exists

    - name: Check if agent-dev venv exists
      ansible.builtin.stat:
        path: "{{ venvs_base }}/{{ arch_name }}/agent-dev/bin/python"
      register: agent_dev_exists

    # ========================================
    # ML-GPU Venv
    # ========================================
    - name: Create ml-gpu venv
      when: not ml_gpu_exists.stat.exists
      block:
        - name: Create ml-gpu virtualenv
          ansible.builtin.command:
            cmd: "{{ python_cmd }} -m venv {{ venvs_base }}/{{ arch_name }}/ml-gpu"
            creates: "{{ venvs_base }}/{{ arch_name }}/ml-gpu/bin/python"

        - name: Upgrade pip in ml-gpu venv
          ansible.builtin.pip:
            name: pip
            state: latest
            virtualenv: "{{ venvs_base }}/{{ arch_name }}/ml-gpu"

        - name: Install PyTorch in ml-gpu venv (CUDA 13.0)
          ansible.builtin.pip:
            name:
              - torch==2.9.1
              - torchvision
              - torchaudio
            extra_args: "--index-url https://download.pytorch.org/whl/cu130"
            virtualenv: "{{ venvs_base }}/{{ arch_name }}/ml-gpu"

        - name: Install ml-gpu packages
          ansible.builtin.pip:
            name: "{{ ml_gpu_packages }}"
            virtualenv: "{{ venvs_base }}/{{ arch_name }}/ml-gpu"

        - name: Register ml-gpu kernel
          ansible.builtin.command:
            cmd: >
              {{ venvs_base }}/{{ arch_name }}/ml-gpu/bin/python -m ipykernel install
              --prefix={{ venvs_base }}/{{ arch_name }}/ml-gpu
              --name=ml-gpu
              --display-name="ML Development ({{ arch_name }})"

    # ========================================
    # Fine-Tuning Venv
    # ========================================
    - name: Create fine-tuning venv
      when: not fine_tuning_exists.stat.exists
      block:
        - name: Create fine-tuning virtualenv
          ansible.builtin.command:
            cmd: "{{ python_cmd }} -m venv {{ venvs_base }}/{{ arch_name }}/fine-tuning"
            creates: "{{ venvs_base }}/{{ arch_name }}/fine-tuning/bin/python"

        - name: Upgrade pip in fine-tuning venv
          ansible.builtin.pip:
            name: pip
            state: latest
            virtualenv: "{{ venvs_base }}/{{ arch_name }}/fine-tuning"

        - name: Install PyTorch in fine-tuning venv (CUDA 13.0)
          ansible.builtin.pip:
            name:
              - torch==2.9.1
              - torchvision
              - torchaudio
            extra_args: "--index-url https://download.pytorch.org/whl/cu130"
            virtualenv: "{{ venvs_base }}/{{ arch_name }}/fine-tuning"

        - name: Install fine-tuning packages
          ansible.builtin.pip:
            name: "{{ fine_tuning_packages }}"
            virtualenv: "{{ venvs_base }}/{{ arch_name }}/fine-tuning"

        - name: Install Unsloth (no deps to avoid torch conflicts)
          ansible.builtin.pip:
            name: git+https://github.com/unslothai/unsloth-zoo.git
            extra_args: "--no-deps"
            virtualenv: "{{ venvs_base }}/{{ arch_name }}/fine-tuning"

        - name: Install Unsloth main package
          ansible.builtin.pip:
            name: "unsloth[cu130onlytorch291] @ git+https://github.com/unslothai/unsloth.git"
            extra_args: "--no-build-isolation --no-deps"
            virtualenv: "{{ venvs_base }}/{{ arch_name }}/fine-tuning"

        - name: Register fine-tuning kernel
          ansible.builtin.command:
            cmd: >
              {{ venvs_base }}/{{ arch_name }}/fine-tuning/bin/python -m ipykernel install
              --prefix={{ venvs_base }}/{{ arch_name }}/fine-tuning
              --name=fine-tuning
              --display-name="Fine-Tuning Lab ({{ arch_name }})"

    # ========================================
    # Agent-Dev Venv
    # ========================================
    - name: Create agent-dev venv
      when: not agent_dev_exists.stat.exists
      block:
        - name: Create agent-dev virtualenv
          ansible.builtin.command:
            cmd: "{{ python_cmd }} -m venv {{ venvs_base }}/{{ arch_name }}/agent-dev"
            creates: "{{ venvs_base }}/{{ arch_name }}/agent-dev/bin/python"

        - name: Upgrade pip in agent-dev venv
          ansible.builtin.pip:
            name: pip
            state: latest
            virtualenv: "{{ venvs_base }}/{{ arch_name }}/agent-dev"

        - name: Install PyTorch in agent-dev venv (CUDA 13.0)
          ansible.builtin.pip:
            name:
              - torch==2.9.1
              - torchvision
              - torchaudio
            extra_args: "--index-url https://download.pytorch.org/whl/cu130"
            virtualenv: "{{ venvs_base }}/{{ arch_name }}/agent-dev"

        - name: Install agent-dev packages
          ansible.builtin.pip:
            name: "{{ agent_dev_packages }}"
            virtualenv: "{{ venvs_base }}/{{ arch_name }}/agent-dev"

        - name: Install openlit without deps (avoid langchain downgrade)
          ansible.builtin.pip:
            name: openlit
            extra_args: "--no-deps"
            virtualenv: "{{ venvs_base }}/{{ arch_name }}/agent-dev"

        - name: Register agent-dev kernel
          ansible.builtin.command:
            cmd: >
              {{ venvs_base }}/{{ arch_name }}/agent-dev/bin/python -m ipykernel install
              --prefix={{ venvs_base }}/{{ arch_name }}/agent-dev
              --name=agent-dev
              --display-name="Agent Development ({{ arch_name }})"

    # ========================================
    # Final Setup
    # ========================================
    - name: Fix ownership of venvs directory
      ansible.builtin.file:
        path: "{{ venvs_base }}"
        owner: 1000
        group: 100
        recurse: true

    - name: Display completion message
      ansible.builtin.debug:
        msg: |
          Venvs bootstrap complete for {{ arch_name }}!

          Created venvs at: {{ venvs_base }}/{{ arch_name }}/
            - ml-gpu: ML development with transformers, datasets, etc.
            - fine-tuning: LLM fine-tuning with Unsloth, peft, trl
            - agent-dev: Agent frameworks with LangChain, CrewAI, AG2

          To add more packages to a venv:
            {{ venvs_base }}/{{ arch_name }}/ml-gpu/bin/pip install <package>

          To create a new custom venv:
            python3 -m venv {{ venvs_base }}/{{ arch_name }}/my-env
            {{ venvs_base }}/{{ arch_name }}/my-env/bin/pip install ipykernel
            {{ venvs_base }}/{{ arch_name }}/my-env/bin/python -m ipykernel install --user --name=my-env
