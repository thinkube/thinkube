{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SeaweedFS Integration Examples\n",
    "\n",
    "This notebook demonstrates how to work with SeaweedFS storage for datasets and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage Locations\n",
    "\n",
    "JupyterHub provides several storage locations:\n",
    "- `/home/jovyan/notebooks` - Persistent notebook storage (SeaweedFS)\n",
    "- `/home/jovyan/datasets` - Shared datasets (SeaweedFS)\n",
    "- `/home/jovyan/models` - Trained models (SeaweedFS)\n",
    "- `/home/jovyan/scratch` - Fast local temporary storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available storage locations\n",
    "storage_paths = {\n",
    "    'notebooks': '/home/jovyan/notebooks',\n",
    "    'datasets': '/home/jovyan/datasets',\n",
    "    'models': '/home/jovyan/models',\n",
    "    'scratch': '/home/jovyan/scratch'\n",
    "}\n",
    "\n",
    "for name, path in storage_paths.items():\n",
    "    if os.path.exists(path):\n",
    "        # Get disk usage\n",
    "        stat = os.statvfs(path)\n",
    "        free_gb = (stat.f_bavail * stat.f_frsize) / (1024**3)\n",
    "        total_gb = (stat.f_blocks * stat.f_frsize) / (1024**3)\n",
    "        print(f\"{name:10} - {path}\")\n",
    "        print(f\"           Free: {free_gb:.2f} GB / Total: {total_gb:.2f} GB\\n\")\n",
    "    else:\n",
    "        print(f\"{name:10} - {path} (not mounted)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample dataset and save to persistent storage\n",
    "np.random.seed(42)\n",
    "data = pd.DataFrame({\n",
    "    'feature1': np.random.randn(1000),\n",
    "    'feature2': np.random.randn(1000),\n",
    "    'target': np.random.randint(0, 2, 1000)\n",
    "})\n",
    "\n",
    "# Save to datasets directory (persistent across nodes)\n",
    "dataset_path = Path('/home/jovyan/datasets/sample_data.csv')\n",
    "data.to_csv(dataset_path, index=False)\n",
    "print(f\"Dataset saved to: {dataset_path}\")\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"File size: {dataset_path.stat().st_size / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from persistent storage\n",
    "loaded_data = pd.read_csv(dataset_path)\n",
    "print(f\"Dataset loaded successfully\")\n",
    "print(loaded_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a simple model and save it\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Split data\n",
    "X = loaded_data[['feature1', 'feature2']]\n",
    "y = loaded_data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "score = model.score(X_test, y_test)\n",
    "print(f\"Model accuracy: {score:.4f}\")\n",
    "\n",
    "# Save model to persistent storage\n",
    "model_path = Path('/home/jovyan/models/sample_model.joblib')\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"Model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from persistent storage\n",
    "loaded_model = joblib.load(model_path)\n",
    "print(f\"Model loaded successfully\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = loaded_model.predict(X_test[:5])\n",
    "print(f\"Sample predictions: {predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Scratch Space for Temporary Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scratch space for temporary large files\n",
    "scratch_file = Path('/home/jovyan/scratch/temp_large_data.npy')\n",
    "\n",
    "# Create a large temporary array\n",
    "large_array = np.random.randn(10000, 1000)\n",
    "np.save(scratch_file, large_array)\n",
    "print(f\"Temporary file saved to scratch: {scratch_file}\")\n",
    "print(f\"File size: {scratch_file.stat().st_size / (1024**2):.2f} MB\")\n",
    "\n",
    "# Note: Files in /scratch are NOT persistent and will be lost when the pod restarts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a project structure in notebooks directory\n",
    "project_name = \"my_ml_project\"\n",
    "project_base = Path(f'/home/jovyan/notebooks/projects/{project_name}')\n",
    "\n",
    "# Create directories\n",
    "dirs_to_create = [\n",
    "    project_base / 'data' / 'raw',\n",
    "    project_base / 'data' / 'processed',\n",
    "    project_base / 'notebooks',\n",
    "    project_base / 'models',\n",
    "    project_base / 'src',\n",
    "    project_base / 'results'\n",
    "]\n",
    "\n",
    "for dir_path in dirs_to_create:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Created: {dir_path}\")\n",
    "\n",
    "# Create a README\n",
    "readme_content = f\"\"\"# {project_name}\n",
    "\n",
    "## Project Structure\n",
    "- `data/` - Dataset storage\n",
    "- `notebooks/` - Jupyter notebooks\n",
    "- `models/` - Trained models\n",
    "- `src/` - Source code\n",
    "- `results/` - Results and outputs\n",
    "\n",
    "Created on: {pd.Timestamp.now()}\n",
    "\"\"\"\n",
    "\n",
    "(project_base / 'README.md').write_text(readme_content)\n",
    "print(f\"\\nProject structure created at: {project_base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistence Verification\n",
    "\n",
    "Files saved to SeaweedFS-backed directories will persist even if:\n",
    "- The notebook server restarts\n",
    "- You switch to a different node\n",
    "- The pod is rescheduled\n",
    "\n",
    "This allows true multi-node flexibility for GPU workloads!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}