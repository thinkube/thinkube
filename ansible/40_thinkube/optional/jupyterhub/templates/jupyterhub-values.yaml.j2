# Copyright 2025 Alejandro Martínez Corriá and the Thinkube contributors
# SPDX-License-Identifier: Apache-2.0

# JupyterHub Helm chart values with dynamic image discovery
# Images discovered at runtime from thinkube-control API
# No fallbacks - fails if dependencies unavailable

hub:
  config:
    JupyterHub:
      # MANDATORY: Keycloak authentication only - no fallbacks
      authenticator_class: generic-oauth
      admin_access: true
      admin_users:
        - {{ admin_username }}
      allow_named_servers: false
      shutdown_on_logout: true

    # Keycloak authentication is mandatory
    GenericOAuthenticator:
      client_id: jupyterhub
      client_secret: "{{ jupyterhub_client_secret }}"
      oauth_callback_url: "https://jupyter.{{ domain_name }}/hub/oauth_callback"
      authorize_url: "https://keycloak.{{ domain_name }}/realms/{{ keycloak_realm }}/protocol/openid-connect/auth"
      token_url: "https://keycloak.{{ domain_name }}/realms/{{ keycloak_realm }}/protocol/openid-connect/token"
      userdata_url: "https://keycloak.{{ domain_name }}/realms/{{ keycloak_realm }}/protocol/openid-connect/userinfo"
      login_service: "Keycloak"
      username_claim: "preferred_username"
      scope:
        - "openid"
        - "profile"
        - "email"
      allow_all: false
      allowed_users:
        - {{ admin_username }}

  extraConfig:
    00-default-url: |
      # Set default URL to JupyterLab
      c.Spawner.default_url = '/lab'

    01-dynamic-profile-generator: |
      # Dynamic profile generation from thinkube-control API
      # NO FALLBACKS - fails if API unavailable
      import requests
      import sys
      import logging

      def get_profile_list(spawner):
          """Dynamically query thinkube-control for available Jupyter images"""
          logging.basicConfig(level=logging.INFO)
          logger = logging.getLogger(__name__)

          try:
              # Query thinkube-control API - NO FALLBACKS
              logger.info("Querying thinkube-control for available images...")
              response = requests.get(
                  'http://thinkube-control-api.thinkube-control:8000/api/v1/images/jupyter',
                  headers={'Accept': 'application/json'},
                  timeout=10
              )

              if response.status_code != 200:
                  logger.error(f"FATAL: thinkube-control API returned {response.status_code}")
                  sys.exit(1)  # Fail immediately - no fallbacks

              images = response.json()
              profiles = []

              for img in images:
                  logger.info(f"Adding profile for image: {img.get('name')}")
                  profile = {
                      'display_name': img.get('display_name', img['name']),
                      'description': img.get('description', ''),
                      'default': img.get('default', False),
                      'kubespawner_override': {
                          'image': f"{{ harbor_registry }}/library/{img['name']}:latest",
                          'image_pull_policy': 'Always'
                      }
                  }

                  # Add GPU requirements if specified
                  if img.get('metadata', {}).get('gpu_required'):
                      profile['kubespawner_override']['node_selector'] = {'nvidia.com/gpu': 'true'}
                      profile['kubespawner_override']['extra_resource_limits'] = {'nvidia.com/gpu': '1'}
                      profile['kubespawner_override']['extra_resource_guarantees'] = {'nvidia.com/gpu': '1'}

                  # Add resource recommendations
                  if 'cpu_limit' in img.get('metadata', {}):
                      profile['kubespawner_override']['cpu_limit'] = img['metadata']['cpu_limit']
                  if 'mem_limit' in img.get('metadata', {}):
                      profile['kubespawner_override']['mem_limit'] = img['metadata']['mem_limit']

                  profiles.append(profile)

              if not profiles:
                  logger.error("FATAL: No Jupyter images available from thinkube-control")
                  sys.exit(1)  # Fail immediately - no images available

              logger.info(f"Successfully loaded {len(profiles)} profiles")
              return profiles

          except requests.exceptions.RequestException as e:
              logger.error(f"FATAL: Failed to connect to thinkube-control: {e}")
              sys.exit(1)  # Fail immediately on connection error
          except Exception as e:
              logger.error(f"FATAL: Unexpected error querying thinkube-control: {e}")
              sys.exit(1)  # Fail immediately on any error

      c.KubeSpawner.profile_list = get_profile_list

proxy:
  secretToken: "{{ jupyterhub_proxy_token | default(lookup('password', '/dev/null chars=hex_digits length=64')) }}"
  service:
    type: ClusterIP
  https:
    enabled: false
  chp:
    pdb:
      enabled: false
    extraCommandLineFlags:
      - "--websocket-max-frame-size=104857600"
      - "--websocket-ping-interval=30000"
      - "--websocket-ping-timeout=60000"

singleuser:
  defaultUrl: "/lab"

  # MANDATORY: SeaweedFS storage - no fallbacks
  storage:
    type: none  # We define volumes manually

  # Hybrid storage approach: SeaweedFS (persistent) + local scratch (performance)
  extraVolumes:
    # SeaweedFS for persistent notebooks (MANDATORY)
    - name: notebooks
      persistentVolumeClaim:
        claimName: jupyter-notebooks-pvc

    # SeaweedFS for datasets (MANDATORY)
    - name: datasets
      persistentVolumeClaim:
        claimName: jupyter-datasets-pvc

    # SeaweedFS for models (MANDATORY)
    - name: models
      persistentVolumeClaim:
        claimName: jupyter-models-pvc

    # Local scratch for fast I/O (per-pod temporary)
    - name: scratch
      emptyDir:
        sizeLimit: 100Gi

  extraVolumeMounts:
    # Primary notebook storage (SeaweedFS - persistent across nodes)
    - name: notebooks
      mountPath: /home/jovyan/notebooks

    # Datasets directory (SeaweedFS - persistent across nodes)
    - name: datasets
      mountPath: /home/jovyan/datasets

    # Models directory (SeaweedFS - persistent across nodes)
    - name: models
      mountPath: /home/jovyan/models

    # Fast local scratch space (emptyDir - temporary)
    - name: scratch
      mountPath: /home/jovyan/scratch

  # Remove all node restrictions to allow scheduling on any GPU node
  nodeSelector: {}
  extraNodeAffinity: {}

  # Enable GPU support
  extraEnv:
    - name: NVIDIA_VISIBLE_DEVICES
      value: "all"
    - name: NVIDIA_DRIVER_CAPABILITIES
      value: "compute,utility"
    - name: JUPYTER_ENABLE_LAB
      value: "yes"
    - name: GRANT_SUDO
      value: "yes"

  # Default resource limits (overridden by dynamic profiles)
  cpu:
    limit: 4
    guarantee: 1
  memory:
    limit: 8G
    guarantee: 2G

  # Allow privilege escalation for sudo
  allowPrivilegeEscalation: true

  # Network policy
  networkPolicy:
    enabled: false

  # Image pull policy
  imagePullPolicy: Always

  # Start timeout (5 minutes for image pull)
  startTimeout: 300

  # Lifecycle hooks for directory setup
  lifecycleHooks:
    postStart:
      exec:
        command:
          - "sh"
          - "-c"
          - |
            # Create notebook directories if they don't exist
            mkdir -p /home/jovyan/notebooks/{projects,experiments,agents,fine-tuning}
            mkdir -p /home/jovyan/datasets/{raw,processed,embeddings}
            mkdir -p /home/jovyan/models/{checkpoints,production,fine-tuned}
            mkdir -p /home/jovyan/scratch/tmp

# Ingress is handled separately in the deployment playbook
ingress:
  enabled: false

# Scheduling configuration (disabled for simplicity)
scheduling:
  userScheduler:
    enabled: false
  podPriority:
    enabled: false
  userPlaceholder:
    enabled: false

# Pre-puller configuration (disabled - images pulled on demand)
prePuller:
  hook:
    enabled: false
  continuous:
    enabled: false

# Culling configuration
cull:
  enabled: true
  timeout: 3600  # 1 hour idle timeout
  every: 600  # Check every 10 minutes
  maxAge: 0  # Don't cull based on age

# Debug mode (disable in production)
debug:
  enabled: false

# Global configuration
global:
  safeToShowValues: false